{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":407317,"sourceType":"datasetVersion","datasetId":181273}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:39:37.587054Z","iopub.execute_input":"2025-12-15T20:39:37.587668Z","iopub.status.idle":"2025-12-15T20:40:54.869718Z","shell.execute_reply.started":"2025-12-15T20:39:37.587643Z","shell.execute_reply":"2025-12-15T20:40:54.868809Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting segmentation-models-pytorch\n  Downloading segmentation_models_pytorch-0.5.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: huggingface-hub>=0.24 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.36.0)\nRequirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.26.4)\nRequirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (11.3.0)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.5.3)\nRequirement already satisfied: timm>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (1.0.19)\nRequirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (0.21.0+cu124)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from segmentation-models-pytorch) (4.67.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (2.32.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24->segmentation-models-pytorch) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.3->segmentation-models-pytorch) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->segmentation-models-pytorch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->segmentation-models-pytorch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->segmentation-models-pytorch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->segmentation-models-pytorch) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.3->segmentation-models-pytorch) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.3->segmentation-models-pytorch) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.24->segmentation-models-pytorch) (2025.10.5)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.3->segmentation-models-pytorch) (2024.2.0)\nDownloading segmentation_models_pytorch-0.5.0-py3-none-any.whl (154 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.8/154.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, segmentation-models-pytorch\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 segmentation-models-pytorch-0.5.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport glob\nimport random\nfrom PIL import Image\nimport tifffile\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nimport torchvision.transforms as T\nimport segmentation_models_pytorch as smp\nfrom segmentation_models_pytorch.metrics import iou_score, f1_score\nfrom tqdm import tqdm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:42:54.544206Z","iopub.execute_input":"2025-12-15T20:42:54.544564Z","iopub.status.idle":"2025-12-15T20:43:05.836743Z","shell.execute_reply.started":"2025-12-15T20:42:54.544531Z","shell.execute_reply":"2025-12-15T20:43:05.836137Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"class LGGDataset(Dataset):\n    def __init__(self, dirs, transform=None):\n        self.samples = []\n        self.transform = transform\n\n        for patient_dir in dirs:            \n            images = [os.path.join(patient_dir, img) for img in os.listdir(patient_dir) if \"_mask.tif\" not in img]\n\n            for img in images:\n                mask = img.replace(\".tif\", \"_mask.tif\")\n\n                image = tifffile.imread(img).astype(np.float32)\n                mask = tifffile.imread(mask).astype(np.float32)\n\n                image = image / 255.0\n                mask = mask / 255.0\n\n                image = np.array(image)\n                mask = np.array(mask)\n                \n                self.samples.append((image, mask))\n                \n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        image, mask = self.samples[idx]\n\n        if self.transform is not None:\n            augmented = self.transform(image=image, mask=mask)\n            image = augmented['image']\n            mask = augmented['mask']\n\n        else:\n            image = torch.tensor(image).permute(2,0,1).float()\n            mask = torch.tensor(mask).float()\n            \n        if mask.ndim == 2:  \n            mask = mask.unsqueeze(0)\n        \n        return image, mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T20:43:10.573233Z","iopub.execute_input":"2025-12-15T20:43:10.573718Z","iopub.status.idle":"2025-12-15T20:43:10.580787Z","shell.execute_reply.started":"2025-12-15T20:43:10.573696Z","shell.execute_reply":"2025-12-15T20:43:10.580029Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"root = \"/kaggle/input/lgg-mri-segmentation/kaggle_3m/\"\n\npatients = sorted([os.path.join(root, p) for p in os.listdir(root)])\npatients = [patient for patient in patients if os.path.isdir(patient)]\nrandom.shuffle(patients)\n\ntrain_patients = patients[:90]\nval_patients = patients[90:]\n\ntrain_transform = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.3),\n    A.RandomRotate90(p=0.5),\n    A.Affine(\n        translate_percent=(0.05, 0.05),\n        scale=(0.95, 1.05),\n        rotate=(-20, 20),\n        p=0.5\n    ),\n    A.ElasticTransform(alpha=50, sigma=50, p=0.3),\n    A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.3),\n    A.RandomBrightnessContrast(p=0.3),\n    #A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\nval_transform = A.Compose([\n    #A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2()\n])\n\ntrain_ds = LGGDataset(train_patients, transform=train_transform)\nval_ds = LGGDataset(val_patients, transform=val_transform)\n\ntrain_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=4, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T21:07:00.375538Z","iopub.execute_input":"2025-12-15T21:07:00.376056Z","iopub.status.idle":"2025-12-15T21:07:27.030037Z","shell.execute_reply.started":"2025-12-15T21:07:00.376035Z","shell.execute_reply":"2025-12-15T21:07:27.029399Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"models = {\n    \"FPN_resnet34\": smp.FPN(\n        encoder_name='resnet34',\n        encoder_weights=\"imagenet\",\n        in_channels=3,\n        classes=1,\n        activation=None,\n    ),\n    \"FPN_efficientnet\": smp.FPN(\n        encoder_name='efficientnet-b0',\n        encoder_weights=\"imagenet\",\n        in_channels=3,\n        classes=1,\n        activation=None,\n    ),\n    \"FPN_vgg16\": smp.FPN(\n        encoder_name='vgg16',\n        encoder_weights=\"imagenet\",\n        in_channels=3,\n        classes=1\n    ),\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T21:07:31.048613Z","iopub.execute_input":"2025-12-15T21:07:31.049320Z","iopub.status.idle":"2025-12-15T21:07:33.206596Z","shell.execute_reply.started":"2025-12-15T21:07:31.049298Z","shell.execute_reply":"2025-12-15T21:07:33.205959Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"metrics = {'FPN_resnet34':[],'FPN_efficientnet':[],'FPN_vgg16':[]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T21:07:35.930838Z","iopub.execute_input":"2025-12-15T21:07:35.931486Z","iopub.status.idle":"2025-12-15T21:07:35.934920Z","shell.execute_reply.started":"2025-12-15T21:07:35.931465Z","shell.execute_reply":"2025-12-15T21:07:35.934110Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class DiceBCELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.dice = smp.losses.DiceLoss(mode=\"binary\")\n        self.bce = nn.BCEWithLogitsLoss()\n\n    def forward(self, pred, target):\n        return self.dice(pred, target) + self.bce(pred, target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T21:07:38.205150Z","iopub.execute_input":"2025-12-15T21:07:38.205433Z","iopub.status.idle":"2025-12-15T21:07:38.210332Z","shell.execute_reply.started":"2025-12-15T21:07:38.205412Z","shell.execute_reply":"2025-12-15T21:07:38.209529Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"import csv\n\ndevice = \"cuda\"\nnum_epochs = 35\n\nfor name in models.keys():\n    with open(f\"{name}_metrics.csv\", mode='w', newline='') as f:\n        writer = csv.writer(f)\n        writer.writerow(['epoch', 'train_loss', 'val_loss', 'IoU', 'Dice'])\n\npatience = 5\nmin_delta = 1e-4\n\nfor name, model in models.items():\n    print(f\"\\nTraining: {name}\\n{'-'*40}\")\n    \n    model.to(device)\n    loss_val = DiceBCELoss()\n\n    if name == \"FPN_vgg16\":\n        lr = 1e-4\n        scheduler_type = \"Cosine\"\n    else:\n        lr = 5e-3\n        scheduler_type = \"ReduceLROnPlateau\"\n        \n    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n\n    if scheduler_type == \"Cosine\":\n        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n            optimizer, T_max=num_epochs, eta_min=1e-6\n        )\n    else:\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='min', factor=0.5, patience=2\n        )\n\n    best_val_loss = np.inf\n    epochs_no_improve = 0\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_losses = []\n\n        for img, mask in tqdm(train_loader, desc=f\"Epoch {epoch:02d} [Train]\", leave=True):\n            img, mask = img.to(device), mask.to(device)\n            pred = model(img)\n            loss = loss_val(pred, mask)\n\n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            train_losses.append(loss.item())\n        \n        model.eval()\n        val_losses, ious, dices = [], [], []\n\n        with torch.no_grad():\n            for img, mask in tqdm(val_loader, desc=f\"Epoch {epoch:02d} [Val]\", leave=True):\n                img, mask = img.to(device), mask.to(device)\n                pred = model(img)\n                loss = loss_val(pred, mask)\n                val_losses.append(loss.item())\n\n                tp, fp, fn, tn = smp.metrics.get_stats(pred, mask.int(), mode='binary', threshold=0.5)\n                iou = iou_score(tp, fp, fn, tn, reduction=\"micro\")\n                dice = f1_score(tp, fp, fn, tn, reduction=\"micro\")\n\n                ious.append(iou.item())\n                dices.append(dice.item())\n        \n        train_loss_avg = np.mean(train_losses)\n        val_loss_avg = np.mean(val_losses)\n        iou_avg = np.nanmean(ious)\n        dice_avg = np.nanmean(dices)\n\n        print(\n            f\"Epoch {epoch:02d} | \"\n            f\"train_loss={train_loss_avg:.4f} | \"\n            f\"val_loss={val_loss_avg:.4f} | \"\n            f\"IoU={iou_avg:.4f} | \"\n            f\"Dice={dice_avg:.4f} | \"\n            f\"lr={scheduler.get_last_lr()[0]:.6f}\"\n        )\n\n        metrics[name].append((train_loss_avg, val_loss_avg, iou_avg, dice_avg))\n\n        with open(f\"{name}_metrics.csv\", mode='a', newline='') as f:\n            writer = csv.writer(f)\n            writer.writerow([epoch, train_loss_avg, val_loss_avg, iou_avg, dice_avg])\n\n        if val_loss_avg + min_delta < best_val_loss:\n            best_val_loss = val_loss_avg\n            epochs_no_improve = 0\n            torch.save(model.state_dict(), f\"{name}_best_weights.pth\")\n        else:\n            epochs_no_improve += 1\n            if epochs_no_improve >= patience:\n                print(f\"Early stopping triggered at epoch {epoch+1}\")\n                break\n            \n        if scheduler_type == \"Cosine\":\n            scheduler.step()\n        else:\n            scheduler.step(val_loss_avg)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T20:43:46.666651Z","iopub.execute_input":"2025-12-08T20:43:46.666994Z","iopub.status.idle":"2025-12-08T21:54:02.358233Z","shell.execute_reply.started":"2025-12-08T20:43:46.666935Z","shell.execute_reply":"2025-12-08T21:54:02.357382Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmodel_names = [\"FPN_resnet34\", \"FPN_efficientnet\", \"FPN_vgg16\"]\n\nmetrics = {}\nfor name in model_names:\n    metrics[name] = []\n    with open(f\"{name}_metrics.csv\", newline='') as f:\n        reader = csv.DictReader(f)\n        for row in reader:\n            train_loss = float(row['train_loss'])\n            val_loss = float(row['val_loss'])\n            iou = float(row['IoU'])\n            dice = float(row['Dice'])\n            metrics[name].append((train_loss, val_loss, iou, dice))\n\nfig, axs = plt.subplots(2, 2, figsize=(14, 10))\naxs = axs.ravel()\n\ntitles = [\"Train Loss\", \"Val Loss\", \"IoU\", \"Dice\"]\nmetric_idx = [0, 1, 2, 3]\n\nfor ax, title, idx in zip(axs, titles, metric_idx):\n    for model in metrics.keys():\n        values = [epoch[idx] for epoch in metrics[model]]\n        ax.plot(values, label=model, linewidth=2)\n\n    ax.set_title(title, fontsize=14)\n    ax.set_xlabel(\"Epoch\")\n    ax.grid(True, alpha=0.3)\n    ax.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T21:07:45.450747Z","iopub.execute_input":"2025-12-15T21:07:45.451422Z","iopub.status.idle":"2025-12-15T21:07:45.470602Z","shell.execute_reply.started":"2025-12-15T21:07:45.451400Z","shell.execute_reply":"2025-12-15T21:07:45.469700Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1308276868.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{name}_metrics.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'FPN_resnet34_metrics.csv'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'FPN_resnet34_metrics.csv'","output_type":"error"}],"execution_count":14},{"cell_type":"code","source":"for name, model in models.items():\n    starter = torch.cuda.Event(enable_timing=True)\n    ender   = torch.cuda.Event(enable_timing=True)\n    \n    repeats = 1000\n    model.to('cuda')\n    model.eval()\n    \n    for img, mask in train_loader:\n        img, mask = img.to('cuda'), mask.to('cuda')\n    \n        with torch.no_grad():\n            starter.record()\n            for _ in range(repeats):\n                model(img)\n            ender.record()\n        \n        torch.cuda.synchronize()\n        total_time = starter.elapsed_time(ender)  \n        latency = total_time / repeats\n        \n        print(f\"Encoder: {name}, Latency: {latency:.3f} ms\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T21:07:59.821823Z","iopub.execute_input":"2025-12-15T21:07:59.822520Z","iopub.status.idle":"2025-12-15T21:09:06.580753Z","shell.execute_reply.started":"2025-12-15T21:07:59.822495Z","shell.execute_reply":"2025-12-15T21:09:06.580003Z"}},"outputs":[{"name":"stdout","text":"Encoder: FPN_resnet34, Latency: 16.075 ms\nEncoder: FPN_efficientnet, Latency: 13.235 ms\nEncoder: FPN_vgg16, Latency: 37.278 ms\n","output_type":"stream"}],"execution_count":15}]}